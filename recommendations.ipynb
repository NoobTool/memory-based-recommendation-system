{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  2.0  0.0  4.0  0.0  4.0  4.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 1        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  5.0  0.0  0.0  3.0  4.0  2.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " 4        4.0  0.0  5.0  0.0  1.0  0.0  3.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      0.0  0.0  5.0  4.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 296      4.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 297      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 298      0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " 299      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " 4        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 299      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  4.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  4.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      5.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  5.0  4.0  4.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  4.0  ...  0.0  0.0  3.0   \n",
       " 4        0.0  4.0  0.0  4.0  3.0  2.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      4.0  0.0  5.0  4.0  2.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  5.0  ...  0.0  0.0  4.0   \n",
       " 199      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  2.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  2.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  3.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Your implementation to predict the missing values\n",
    "(Put all your implementation for your algorithm in the following cell only to handle the missing values; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3"
   },
   "outputs": [],
   "source": [
    "## Put all your implementation for your solutioin in this cell only to predict the missing values; \n",
    "## NOTE 1: DO NOT change anything in the rest of the cells in this framework, \n",
    "## otherwise the changes might cause errors and make your implementation invalid.\n",
    "\n",
    "## Note 2: \n",
    "## The user-item rating matrix is imputed_train_ds, \n",
    "## and the missing values are those 0s in imputed_train_ds. \n",
    "## You are required to predict them by using the solution in the given report. \n",
    "\n",
    "## The following parameters are required in the given report, \n",
    "## which is named \"Effective Missing Data Prediction for Collaborative Filtering\", \n",
    "## and you will need to use them. But, please do not change their values. \n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "\n",
    "\n",
    "### Code written by Ram\n",
    "\n",
    "# Matrix containing user-based relations\n",
    "pearson_mat = np.zeros((len(df['user_id'].unique()),len(df['user_id'].unique())))\n",
    "\n",
    "for i,user_vector1 in enumerate(imputed_train_ds):\n",
    "    for j,user_vector2 in enumerate(imputed_train_ds):\n",
    "        \n",
    "        # Masking the vectors with rating 0\n",
    "        mask_i = user_vector1>0\n",
    "        mask_j = user_vector2>0\n",
    "        \n",
    "        # Finding intersection of items between users\n",
    "        corratedItems = np.intersect1d(np.where(mask_i),np.where(mask_j))\n",
    "        \n",
    "        # Skipping if there are no common items\n",
    "        if len(corratedItems)==0:\n",
    "            continue\n",
    "        \n",
    "        # Removing items with 0 rating\n",
    "        user_masked_vector1 = user_vector1[mask_i]\n",
    "        user_masked_vector2 = user_vector2[mask_j]\n",
    "        \n",
    "        # Finding mean of every user\n",
    "        mean_vector1 = np.sum(user_masked_vector1)/(np.sum(np.clip(user_vector1,0,1))+EPSILON)\n",
    "        mean_vector2 = np.sum(user_masked_vector2)/(np.sum(np.clip(user_vector2,0,1))+EPSILON)\n",
    "        \n",
    "        # Subtracting mean\n",
    "        subtracted_i = user_vector1[corratedItems]-mean_vector1\n",
    "        subtracted_j = user_vector2[corratedItems]-mean_vector2\n",
    "        \n",
    "        # Multiplying the subtracted mean with each other\n",
    "        numerator = subtracted_i * subtracted_j\n",
    "        \n",
    "        # Taking the summition\n",
    "        numerator = np.sum(numerator)\n",
    "        \n",
    "        # Squaring the values for denominator\n",
    "        squared_i = np.square(subtracted_i)\n",
    "        squared_j = np.square(subtracted_j)\n",
    "        \n",
    "        # Taking the squareroot\n",
    "        sqrt_i = np.sqrt(np.sum(squared_i))\n",
    "        sqrt_j = np.sqrt(np.sum(squared_j))\n",
    "        \n",
    "        # Completing the denominator\n",
    "        denominator = sqrt_i*sqrt_j\n",
    "        \n",
    "        # The similarity\n",
    "        sim = numerator/(denominator+EPSILON)\n",
    "        \n",
    "        # The final similarity with significance weighting\n",
    "        pearson_mat[i][j] = (min(len(corratedItems),GAMMA)/GAMMA)*sim\n",
    "        \n",
    "### Item-based interaction matrix\n",
    "item_mat = np.zeros((len(df['item_id'].unique()),len(df['item_id'].unique())))\n",
    "\n",
    "for i,item_i in enumerate(imputed_train_ds.T):\n",
    "    \n",
    "    # Masking the vectors with rating 0\n",
    "    mask_i = item_i>0\n",
    "                    \n",
    "    for j,item_j in enumerate(imputed_train_ds.T):\n",
    "        \n",
    "        # Masking the vectors with rating 0\n",
    "        mask_j = item_j>0\n",
    "        \n",
    "        # Finding intersection of items between users\n",
    "        corratedIndices = np.intersect1d(np.where(mask_i),np.where(mask_i))\n",
    "        \n",
    "         # Skipping if there are no common items\n",
    "        if(len(corratedIndices)==0):\n",
    "            continue\n",
    "        \n",
    "        # Finding mean of every user\n",
    "        mean_item_i = np.sum(item_i)/np.sum(np.clip(item_i,0,1))+EPSILON\n",
    "        mean_item_j = np.sum(item_j)/np.sum(np.clip(item_j,0,1))+EPSILON\n",
    "        \n",
    "         # Subtracting mean from item ratings\n",
    "        subtracted_item_i = item_i[corratedIndices] - mean_item_i\n",
    "        subtracted_item_j = item_j[corratedIndices] - mean_item_j\n",
    "        \n",
    "        # Multiplying the subtracted mean with each other\n",
    "        subtracted = subtracted_item_i*subtracted_item_j\n",
    "        \n",
    "        # Summing the subtracted values to get the numerator\n",
    "        numerator = np.sum(subtracted)\n",
    "        \n",
    "        # Finding the squareroot of sum of the squares of subtracted values\n",
    "        sqrt_i = np.sqrt(np.sum(np.square(subtracted_item_i)))\n",
    "        sqrt_j = np.sqrt(np.sum(np.square(subtracted_item_j)))\n",
    "        \n",
    "        # Multiplying the squareroot to find the denominator\n",
    "        denominator = sqrt_i*sqrt_j\n",
    "        \n",
    "        # Finding the similarity between the items\n",
    "        sim = numerator/denominator+EPSILON\n",
    "        \n",
    "        # The item matrix with significance weighting\n",
    "        item_mat[i][j] = (min(len(corratedIndices),DELTA)/DELTA)*sim\n",
    "        \n",
    "        \n",
    "k=10\n",
    "np_predictions = np.zeros((imputed_train_ds.shape[0],imputed_train_ds.shape[1]))\n",
    "np_predictions2 = np.zeros((imputed_train_ds.shape[0],imputed_train_ds.shape[1]))\n",
    "\n",
    "## Predictions\n",
    "\n",
    "# User-based predictions\n",
    "for (i,j),rating in np.ndenumerate(imputed_train_ds):\n",
    "    if rating==0:\n",
    "        \n",
    "        # Sorting the similar users list in ascending order\n",
    "        sim_users_list = np.argsort(pearson_mat[i])\n",
    "        \n",
    "        # Filtering the above list with values only above ITA\n",
    "        sim_users_ITA = sim_users_list>ITA\n",
    "        sim_users_list = sim_users_list[sim_users_ITA]\n",
    "        \n",
    "        # Taking out top k similar users\n",
    "        sim_users_id = sim_users_list[-k:]\n",
    "        \n",
    "        # Storing values and users in different variables\n",
    "        sim_val = pearson_mat[i][sim_users_id]\n",
    "        sim_users = imputed_train_ds[sim_users_id]\n",
    "        \n",
    "        # Finding out the mean of current user\n",
    "        curr_user_mean = np.sum(imputed_train_ds[i]) / (np.sum(np.clip(imputed_train_ds[i], 0, 1)) + EPSILON)\n",
    "        \n",
    "        # Finding the mean of the users used to compare with\n",
    "        sim_users_mean = np.sum(sim_users,axis=1)/ (np.sum(np.clip(sim_users, 0, 1),axis=1) + EPSILON)\n",
    "        \n",
    "        masked_j = sim_users[:,j]>0\n",
    "        \n",
    "        # Subtracting mean from each user_item\n",
    "        subtracted_mean = sim_users[masked_j,j]-sim_users_mean[masked_j]\n",
    "        \n",
    "        # Summing up the multiplication of all\n",
    "        numerator = np.sum(sim_val[masked_j]*subtracted_mean)\n",
    "        denominator = np.sum(sim_val[masked_j])\n",
    "        \n",
    "        # Filling the predictions matrix with the calculated values\n",
    "        np_predictions[i][j] = curr_user_mean + (numerator/(denominator+EPSILON))\n",
    "        np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "        \n",
    "# Item-based predictions\n",
    "for (i, j), rating in np.ndenumerate(imputed_train_ds):\n",
    "    if rating == 0:\n",
    "        \n",
    "        # Sorting the similar users list in ascending order\n",
    "        sim_items_list = np.argsort(item_mat[j])\n",
    "        \n",
    "        # Filtering the above list with values only above ITA\n",
    "        sim_items_THETA = sim_items_list>THETA\n",
    "        sim_items_list = sim_items_list[sim_items_THETA]\n",
    "        \n",
    "        # Taking out top k similar users\n",
    "        sim_items_id = sim_items_list[-k:]\n",
    "        \n",
    "        # Storing values and users in different variables\n",
    "        sim_val = item_mat[j][sim_items_id]\n",
    "        sim_items = imputed_train_ds.T[sim_items_id]\n",
    "        \n",
    "        # Finding the mean of the current item\n",
    "        item_mean = np.sum(imputed_train_ds.T[j]) / (np.sum(np.clip(imputed_train_ds.T[j], 0, 1)) + EPSILON)\n",
    "        \n",
    "        # Finding the mean of the users used to compare with\n",
    "        sim_items_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "        \n",
    "        # Clipping similar items\n",
    "        clipped_val = np.clip(sim_items[:, i], 0, 1)\n",
    "        \n",
    "        # Assigning numerator\n",
    "        numerator = sim_val * (sim_items[:, i] - sim_items_mean)\n",
    "        \n",
    "        # Filtering unrated items\n",
    "        numerator*=clipped_val\n",
    "        numerator = np.sum(numerator)\n",
    "        \n",
    "        # Concluding denominator\n",
    "        denominator = (np.sum(sim_val * clipped_val))\n",
    "                       \n",
    "        np_predictions2[i][j] = item_mean + numerator /( denominator  + EPSILON)\n",
    "        np_predictions2[i][j] = np.clip(np_predictions2[i][j], 0, 5)\n",
    "\n",
    "## Inducing predicted values to missing values present in the data\n",
    "prediction_mat = np.zeros((np_predictions.shape[0],np_predictions.shape[1]))\n",
    "\n",
    "for (i,j),rating in np.ndenumerate(np_predictions):\n",
    "    \n",
    "    if(rating==0 and np_predictions2[i][j]!=0):\n",
    "        prediction_mat[i][j] = np_predictions2[i][j]\n",
    "        \n",
    "    elif(rating!=0 and np_predictions2[i][j]==0):\n",
    "        prediction_mat[i][j] = np_predictions[i][j]\n",
    "    \n",
    "    elif(rating!=0 and np_predictions2[i][j]!=0):\n",
    "        prediction_mat[i][j] = (LAMBDA*np_predictions[i][j]) + ((1-LAMBDA)*np_predictions2[i][j])\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "imputed_train_ds = prediction_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.581753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.660598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.467222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.019763</td>\n",
       "      <td>3.569144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.018394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.799147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.053680</td>\n",
       "      <td>3.765139</td>\n",
       "      <td>3.449745</td>\n",
       "      <td>3.622115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.373278</td>\n",
       "      <td>4.939256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.687125</td>\n",
       "      <td>3.580253</td>\n",
       "      <td>4.444808</td>\n",
       "      <td>4.016255</td>\n",
       "      <td>4.038264</td>\n",
       "      <td>3.831367</td>\n",
       "      <td>...</td>\n",
       "      <td>2.419894</td>\n",
       "      <td>4.205243</td>\n",
       "      <td>3.785297</td>\n",
       "      <td>3.344544</td>\n",
       "      <td>4.161691</td>\n",
       "      <td>3.390603</td>\n",
       "      <td>1.558498</td>\n",
       "      <td>3.287280</td>\n",
       "      <td>3.643226</td>\n",
       "      <td>3.797516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.183708</td>\n",
       "      <td>3.858869</td>\n",
       "      <td>3.892563</td>\n",
       "      <td>3.620879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.401975</td>\n",
       "      <td>3.779914</td>\n",
       "      <td>4.669088</td>\n",
       "      <td>3.020150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.986957</td>\n",
       "      <td>3.559077</td>\n",
       "      <td>3.813724</td>\n",
       "      <td>4.419235</td>\n",
       "      <td>3.882806</td>\n",
       "      <td>3.564738</td>\n",
       "      <td>3.374836</td>\n",
       "      <td>3.710950</td>\n",
       "      <td>3.606957</td>\n",
       "      <td>3.875243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.934184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.258543</td>\n",
       "      <td>3.529573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.645551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.731490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.473887</td>\n",
       "      <td>3.332913</td>\n",
       "      <td>3.673560</td>\n",
       "      <td>2.952169</td>\n",
       "      <td>1.841322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.291298</td>\n",
       "      <td>3.264462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.202663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.431336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.359742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.970976</td>\n",
       "      <td>2.985576</td>\n",
       "      <td>...</td>\n",
       "      <td>3.039851</td>\n",
       "      <td>3.083481</td>\n",
       "      <td>3.082365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.469846</td>\n",
       "      <td>3.003057</td>\n",
       "      <td>3.173929</td>\n",
       "      <td>2.412892</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3.779814</td>\n",
       "      <td>2.268861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.792787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.589836</td>\n",
       "      <td>2.662405</td>\n",
       "      <td>2.529035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.359504</td>\n",
       "      <td>1.797482</td>\n",
       "      <td>2.943358</td>\n",
       "      <td>2.674360</td>\n",
       "      <td>2.764667</td>\n",
       "      <td>1.458235</td>\n",
       "      <td>1.527491</td>\n",
       "      <td>3.177193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.639480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>3.348096</td>\n",
       "      <td>4.120869</td>\n",
       "      <td>4.326042</td>\n",
       "      <td>3.468269</td>\n",
       "      <td>3.518608</td>\n",
       "      <td>3.986663</td>\n",
       "      <td>...</td>\n",
       "      <td>2.970124</td>\n",
       "      <td>2.397138</td>\n",
       "      <td>3.548340</td>\n",
       "      <td>3.312995</td>\n",
       "      <td>3.550024</td>\n",
       "      <td>2.661550</td>\n",
       "      <td>1.193254</td>\n",
       "      <td>3.267224</td>\n",
       "      <td>1.667009</td>\n",
       "      <td>3.465007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4.215449</td>\n",
       "      <td>4.385284</td>\n",
       "      <td>4.305475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.785224</td>\n",
       "      <td>4.447656</td>\n",
       "      <td>4.672000</td>\n",
       "      <td>4.723955</td>\n",
       "      <td>4.341439</td>\n",
       "      <td>4.271970</td>\n",
       "      <td>...</td>\n",
       "      <td>3.027945</td>\n",
       "      <td>3.935733</td>\n",
       "      <td>4.154304</td>\n",
       "      <td>3.760014</td>\n",
       "      <td>3.427416</td>\n",
       "      <td>3.641603</td>\n",
       "      <td>3.982757</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.919506</td>\n",
       "      <td>3.916202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.664052</td>\n",
       "      <td>2.956111</td>\n",
       "      <td>3.395053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218173</td>\n",
       "      <td>1.861516</td>\n",
       "      <td>2.934168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.152368</td>\n",
       "      <td>3.417271</td>\n",
       "      <td>...</td>\n",
       "      <td>3.330574</td>\n",
       "      <td>3.012024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.043877</td>\n",
       "      <td>1.046334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.933137</td>\n",
       "      <td>3.601184</td>\n",
       "      <td>2.950766</td>\n",
       "      <td>2.660998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4.311286</td>\n",
       "      <td>3.437808</td>\n",
       "      <td>4.116131</td>\n",
       "      <td>4.240754</td>\n",
       "      <td>3.700612</td>\n",
       "      <td>3.121571</td>\n",
       "      <td>3.909043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.442593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.594604</td>\n",
       "      <td>3.726666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.050247</td>\n",
       "      <td>3.348085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.221679</td>\n",
       "      <td>3.548553</td>\n",
       "      <td>3.355417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    4.581753  0.000000  3.660598  0.000000  3.467222  0.000000  0.000000   \n",
       "1    0.000000  3.373278  4.939256  0.000000  3.687125  3.580253  4.444808   \n",
       "2    4.183708  3.858869  3.892563  3.620879  0.000000  3.401975  3.779914   \n",
       "3    0.000000  2.934184  0.000000  3.258543  3.529573  0.000000  0.000000   \n",
       "4    0.000000  3.202663  0.000000  3.431336  0.000000  3.359742  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  3.779814  2.268861  0.000000  0.000000  2.792787  0.000000  2.589836   \n",
       "296  0.000000  3.500880  0.000000  3.246436  3.348096  4.120869  4.326042   \n",
       "297  4.215449  4.385284  4.305475  0.000000  4.785224  4.447656  4.672000   \n",
       "298  2.664052  2.956111  3.395053  0.000000  3.218173  1.861516  2.934168   \n",
       "299  4.311286  3.437808  4.116131  4.240754  3.700612  3.121571  3.909043   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    4.019763  3.569144  0.000000  ...  3.018394  0.000000  0.000000   \n",
       "1    4.016255  4.038264  3.831367  ...  2.419894  4.205243  3.785297   \n",
       "2    4.669088  3.020150  0.000000  ...  1.986957  3.559077  3.813724   \n",
       "3    0.000000  3.645551  0.000000  ...  1.731490  0.000000  3.473887   \n",
       "4    0.000000  2.970976  2.985576  ...  3.039851  3.083481  3.082365   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  2.662405  2.529035  0.000000  ...  2.359504  1.797482  2.943358   \n",
       "296  3.468269  3.518608  3.986663  ...  2.970124  2.397138  3.548340   \n",
       "297  4.723955  4.341439  4.271970  ...  3.027945  3.935733  4.154304   \n",
       "298  0.000000  2.152368  3.417271  ...  3.330574  3.012024  0.000000   \n",
       "299  0.000000  0.000000  3.442593  ...  0.000000  3.594604  3.726666   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    3.799147  0.000000  0.000000  3.053680  3.765139  3.449745  3.622115  \n",
       "1    3.344544  4.161691  3.390603  1.558498  3.287280  3.643226  3.797516  \n",
       "2    4.419235  3.882806  3.564738  3.374836  3.710950  3.606957  3.875243  \n",
       "3    3.332913  3.673560  2.952169  1.841322  0.000000  3.291298  3.264462  \n",
       "4    0.000000  0.000000  1.469846  3.003057  3.173929  2.412892  0.000000  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  2.674360  2.764667  1.458235  1.527491  3.177193  0.000000  2.639480  \n",
       "296  3.312995  3.550024  2.661550  1.193254  3.267224  1.667009  3.465007  \n",
       "297  3.760014  3.427416  3.641603  3.982757  4.600000  3.919506  3.916202  \n",
       "298  3.043877  1.046334  0.000000  1.933137  3.601184  2.950766  2.660998  \n",
       "299  0.000000  3.050247  3.348085  0.000000  3.221679  3.548553  3.355417  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19433452,  0.04046047,  0.62382812, ...,  0.21078391,\n",
       "         0.07517011, -0.5856483 ],\n",
       "       [ 0.34948738,  0.50167079,  0.20798487, ...,  0.57602789,\n",
       "         0.62314417,  0.21467716],\n",
       "       [ 0.59471376,  0.27149825,  0.56048777, ...,  0.655147  ,\n",
       "         0.81728031,  0.58021325],\n",
       "       ...,\n",
       "       [-0.34524592,  0.18517001, -0.00779502, ..., -0.14471385,\n",
       "         0.08747431,  0.43615217],\n",
       "       [ 0.39528873,  0.43940098,  0.07606676, ...,  0.16376734,\n",
       "         0.18582829,  0.72253193],\n",
       "       [ 0.28577773,  0.30786392,  0.12933753, ...,  0.42801929,\n",
       "         0.35121057,  0.33231439]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 3.22804324,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 4.22202592, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 4.37742322,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [4.29209929, 0.        , 4.6677238 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 3.44100324, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.755930374411552, RMSE: 0.9691529370013368\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
